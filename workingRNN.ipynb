{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn transformers datasets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b67dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from Dependencies.AdditionalFunctions import topK_one_hot, smooth_multi_hot\n",
    "from Dependencies.MovieDataset import MovieGenresDataset\n",
    "from Dependencies.RNN_model_class import RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74bf09",
   "metadata": {},
   "source": [
    "### Initialize Model and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a080ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "my_rnn = RNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e624f5",
   "metadata": {},
   "source": [
    "### Initialize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e332b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgd_ds = MovieGenresDataset()\n",
    "movie_genre_ds = mgd_ds.getDs()\n",
    "movie_id_loc = mgd_ds.get_classes()\n",
    "\n",
    "# This value will be used for padding label sequences\n",
    "pad_value = -1 # Using -1 is safer than a magic number like 5555"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ac855",
   "metadata": {},
   "source": [
    "### **Training Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(rnn, optimizer, dev, train_loader, batch_size=16):\n",
    "    rnn.train() # Set the model to training mode\n",
    "    loss_arr = []\n",
    "    l1_grad_sq = []\n",
    "    l2_grad_sq = []\n",
    "\n",
    "    # --- MEMORY & EFFICIENCY FIX: BATCH-CENTRIC TRAINING --- \n",
    "    # The original code iterated one-by-one inside a batch, which is inefficient \n",
    "    # and can lead to memory issues. This new loop processes the entire batch at once.\n",
    "    for i, (movie_ovw_batch, target_batch) in enumerate(train_loader):\n",
    "        # Move data to the selected device (GPU/CPU)\n",
    "        movie_ovw_batch = movie_ovw_batch.to(dev)\n",
    "        target_batch = target_batch.to(dev)\n",
    "\n",
    "        # --- Prepare targets for the entire batch ---\n",
    "        # This list will hold the processed multi-hot encoded targets for each item in the batch\n",
    "        classes_list = []\n",
    "        for target in target_batch:\n",
    "            # Filter out padding values from the target tensor\n",
    "            valid_targets = target[target != pad_value]\n",
    "            one_hot_target = topK_one_hot(valid_targets.cpu().numpy(), 19) # Assuming topK works with numpy\n",
    "            smoothed_target = smooth_multi_hot(torch.tensor(one_hot_target), len(valid_targets))\n",
    "            classes_list.append(smoothed_target)\n",
    "        \n",
    "        # Stack the list of tensors into a single batch tensor\n",
    "        classes = torch.stack(classes_list).to(dev)\n",
    "\n",
    "        # --- Forward Pass ---\n",
    "        y_hat = rnn.forward(movie_ovw_batch)\n",
    "\n",
    "        # --- Loss Calculation ---\n",
    "        loss_func = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_func(y_hat, classes)\n",
    "\n",
    "        # --- Backpropagation ---\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=1.0) # Gradient clipping\n",
    "        \n",
    "        # Store the layer's squared gradient norm *before* the optimizer step\n",
    "        if rnn.rnnL1.weight_hh.grad is not None:\n",
    "            l1_grad_sq.append(rnn.rnnL1.weight_hh.grad.norm().item()**2)\n",
    "            l2_grad_sq.append(rnn.rnnL2.weight_hh.grad.norm().item()**2)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        loss_arr.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 10 == 0: # Print progress every 10 batches\n",
    "            print(f\"Batch {i+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "            # For debugging memory, uncomment the line below:\n",
    "            # print(torch.cuda.memory_summary(device=dev))\n",
    "    \n",
    "    print(\"Epoch finished.\")\n",
    "    # Save tracking data\n",
    "    df = pd.DataFrame({\n",
    "        'l1_gradient_sq': l1_grad_sq,\n",
    "        'l2_gradient_sq': l2_grad_sq,\n",
    "        'loss_arr': loss_arr\n",
    "    })\n",
    "    df.to_csv(\"track.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419da48",
   "metadata": {},
   "source": [
    "### **Dataset and DataLoader Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc887c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class MovieOverviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_overviews, id_loc_set):\n",
    "        self.tokenized_ovw = tokenized_overviews\n",
    "        self.id_loc_set = id_loc_set\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenized_ovw[idx], torch.tensor(self.id_loc_set[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id_loc_set)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    \n",
    "    # Pad sequences (features)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    \n",
    "    # Pad labels (targets)\n",
    "    padded_labels = pad_sequence(labels, batch_first=True, padding_value=pad_value)\n",
    "    \n",
    "    return padded_sequences, padded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419da49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: This cell pre-processes all movie overviews into embeddings.\n",
    "# This should be run only ONCE to create the 'overview_embs.pt' file.\n",
    "# Running this every time would be very slow.\n",
    "# It saves the embeddings to the CPU to avoid taking up GPU memory.\n",
    "\n",
    "import os\n",
    "\n",
    "embedding_file = \"overview_embs.pt\"\n",
    "\n",
    "if not os.path.exists(embedding_file):\n",
    "    print(\"Embedding file not found. Creating embeddings...\")\n",
    "    overview_ds = []\n",
    "    # Use a temporary model on the correct device for tokenization\n",
    "    temp_model = RNN().to(device)\n",
    "    for i, overview in enumerate(movie_genre_ds[\"overview\"]):\n",
    "        # We move the embeddings to the CPU before storing them in the list\n",
    "        tokenized_ovw = temp_model.tokenize_input(overview, device=device).cpu()\n",
    "        overview_ds.append(tokenized_ovw)\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Processed {i+1}/{len(movie_genre_ds['overview'])} overviews\")\n",
    "    \n",
    "    torch.save(overview_ds, embedding_file)\n",
    "    print(f\"Saved embeddings to {embedding_file}\")\n",
    "    del temp_model # Free up memory\n",
    "else:\n",
    "    print(f\"Loading embeddings from {embedding_file}\")\n",
    "\n",
    "# Load the pre-computed embeddings\n",
    "tokenized_overview_tensors = torch.load(embedding_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c08a3",
   "metadata": {},
   "source": [
    "### **Train RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    BATCH_SIZE = 16 # Defining batch size as a variable\n",
    "\n",
    "    optimizer = optim.Adam(params=my_rnn.parameters(), lr=0.001)\n",
    "\n",
    "    # Create the dataset instance with the pre-loaded embeddings\n",
    "    full_dataset = MovieOverviewDataset(tokenized_overview_tensors, movie_id_loc)\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_ds, test_ds = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(dataset=train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(dataset=test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    epoch_train(my_rnn, optimizer=optimizer, dev=device, train_loader=train_loader, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    print(\"Training complete. Saving model...\")\n",
    "    torch.save(my_rnn.state_dict(), \"model_parameters.pt\")\n",
    "    print(\"Model saved to model_parameters.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
