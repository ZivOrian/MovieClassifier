{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn transformers datasets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b67dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\orian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from Dependencies.Early_Stop import EarlyStopping\n",
    "from Dependencies.AdditionalFunctions import topK_one_hot, smooth_multi_hot\n",
    "from Dependencies.MovieDataset import MovieGenresDataset, MovieOverviewDataset, collate_fn, PAD_VALUE, EPOCH_NUMBER\n",
    "from Dependencies.RNN_model_class import RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74bf09",
   "metadata": {},
   "source": [
    "### Initialize Model and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a080ae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e624f5",
   "metadata": {},
   "source": [
    "### Initialize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e332b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgd_ds = MovieGenresDataset()\n",
    "movie_genre_ds = mgd_ds.getDs()\n",
    "movie_id_loc = mgd_ds.get_classes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5224125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_smoothed_list(target_batch, class_lst):\n",
    "    \"\"\"\n",
    "    Create smoothed multi-hot targets from batch of genre indices.\n",
    "    Properly handles padding (values == PAD_VALUE).\n",
    "    \n",
    "    Args:\n",
    "        target_batch: Tensor of shape (batch_size, max_num_genres) with genre indices\n",
    "        class_lst: List to append results to\n",
    "        PAD_VALUE: Value used for padding (default: -1)\n",
    "    \n",
    "    Returns:\n",
    "        class_lst with smoothed targets appended\n",
    "    \"\"\"\n",
    "    for idx, target in enumerate(target_batch):\n",
    "        # Filter out padding values\n",
    "        valid_targets = target[target != PAD_VALUE]\n",
    "        \n",
    "        # ✅ CRITICAL FIX: Handle all-padding case (empty valid_targets)\n",
    "        if len(valid_targets) == 0:\n",
    "            # This sample has no valid genre labels (all padding)\n",
    "            # Use uniform distribution as fallback\n",
    "            print(f\"⚠️ Sample {idx} in batch has no valid labels (all padding), using uniform distribution\")\n",
    "            smoothed_target = torch.ones(19, dtype=torch.float32) / 19\n",
    "            class_lst.append(smoothed_target)\n",
    "            continue\n",
    "        \n",
    "        # Convert to CPU numpy for one-hot encoding\n",
    "        valid_targets_np = valid_targets.cpu().numpy()\n",
    "        \n",
    "        # ✅ Additional validation: check for invalid indices\n",
    "        if (valid_targets_np < 0).any() or (valid_targets_np >= 19).any():\n",
    "            print(f\"⚠️ Sample {idx} has invalid genre indices: {valid_targets_np}\")\n",
    "            smoothed_target = torch.ones(19, dtype=torch.float32) / 19\n",
    "            class_lst.append(smoothed_target)\n",
    "            continue\n",
    "        \n",
    "        # Create one-hot encoding\n",
    "        one_hot_target = topK_one_hot(valid_targets_np.tolist(), 19)\n",
    "        \n",
    "        # Apply smoothing (this now handles edge cases internally)\n",
    "        smoothed_target = smooth_multi_hot(\n",
    "            torch.tensor(one_hot_target, dtype=torch.float32), \n",
    "            num_valid_labels=len(valid_targets)\n",
    "        )\n",
    "        \n",
    "        # ✅ Final validation (belt and suspenders approach)\n",
    "        if torch.isnan(smoothed_target).any() or torch.isinf(smoothed_target).any():\n",
    "            print(f\"⚠️ Sample {idx} produced NaN/Inf after smoothing, using uniform distribution\")\n",
    "            smoothed_target = torch.ones(19, dtype=torch.float32) / 19\n",
    "        \n",
    "        class_lst.append(smoothed_target)\n",
    "    \n",
    "    return class_lst\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def diagnose_batch(movie_ovw_batch, y_hat, classes, batch_idx):\n",
    "    \"\"\"\n",
    "    Comprehensive diagnostics to find the root cause\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"DIAGNOSTICS FOR BATCH {batch_idx}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 1. Input statistics\n",
    "    print(\"\\n1. INPUT EMBEDDINGS:\")\n",
    "    print(f\"   Shape: {movie_ovw_batch.shape}\")\n",
    "    print(f\"   Mean: {movie_ovw_batch.mean().item():.6f}\")\n",
    "    print(f\"   Std: {movie_ovw_batch.std().item():.6f}\")\n",
    "    print(f\"   Min: {movie_ovw_batch.min().item():.6f}\")\n",
    "    print(f\"   Max: {movie_ovw_batch.max().item():.6f}\")\n",
    "    print(f\"   Contains NaN: {torch.isnan(movie_ovw_batch).any().item()}\")\n",
    "    print(f\"   Contains Inf: {torch.isinf(movie_ovw_batch).any().item()}\")\n",
    "    \n",
    "    # Check for zero variance (dead features)\n",
    "    if movie_ovw_batch.std().item() < 1e-6:\n",
    "        print(f\"   ⚠️ WARNING: Input has very low variance (nearly constant)\")\n",
    "    \n",
    "    # 2. Model output (logits) statistics\n",
    "    print(\"\\n2. MODEL OUTPUT (LOGITS):\")\n",
    "    print(f\"   Shape: {y_hat.shape}\")\n",
    "    print(f\"   Mean: {y_hat.mean().item():.6f}\")\n",
    "    print(f\"   Std: {y_hat.std().item():.6f}\")\n",
    "    print(f\"   Min: {y_hat.min().item():.6f}\")\n",
    "    print(f\"   Max: {y_hat.max().item():.6f}\")\n",
    "    print(f\"   Contains NaN: {torch.isnan(y_hat).any().item()}\")\n",
    "    print(f\"   Contains Inf: {torch.isinf(y_hat).any().item()}\")\n",
    "    \n",
    "    # Check for extreme logits\n",
    "    extreme_negative = (y_hat < -50).sum().item()\n",
    "    extreme_positive = (y_hat > 50).sum().item()\n",
    "    if extreme_negative > 0:\n",
    "        print(f\"   ⚠️ WARNING: {extreme_negative} logits < -50 (will cause underflow)\")\n",
    "    if extreme_positive > 0:\n",
    "        print(f\"   ⚠️ WARNING: {extreme_positive} logits > 50 (will cause overflow)\")\n",
    "    \n",
    "    # 3. Target statistics\n",
    "    print(\"\\n3. TARGETS:\")\n",
    "    print(f\"   Shape: {classes.shape}\")\n",
    "    print(f\"   Mean: {classes.mean().item():.6f}\")\n",
    "    print(f\"   Std: {classes.std().item():.6f}\")\n",
    "    print(f\"   Min: {classes.min().item():.6f}\")\n",
    "    print(f\"   Max: {classes.max().item():.6f}\")\n",
    "    print(f\"   Contains NaN: {torch.isnan(classes).any().item()}\")\n",
    "    print(classes)\n",
    "    \n",
    "    # 4. Loss computation simulation\n",
    "    print(\"\\n4. LOSS COMPUTATION CHECK:\")\n",
    "    with torch.no_grad():\n",
    "        # Manually compute BCE with logits to see where it fails\n",
    "        sigmoid_output = torch.sigmoid(y_hat)\n",
    "        print(f\"   Sigmoid output range: [{sigmoid_output.min().item():.6f}, {sigmoid_output.max().item():.6f}]\")\n",
    "        \n",
    "        # Check for numerical issues in sigmoid\n",
    "        zeros_in_sigmoid = (sigmoid_output == 0).sum().item()\n",
    "        ones_in_sigmoid = (sigmoid_output == 1).sum().item()\n",
    "        if zeros_in_sigmoid > 0:\n",
    "            print(f\"   ⚠️ WARNING: {zeros_in_sigmoid} sigmoid outputs exactly 0 (underflow)\")\n",
    "        if ones_in_sigmoid > 0:\n",
    "            print(f\"   ⚠️ WARNING: {ones_in_sigmoid} sigmoid outputs exactly 1 (overflow)\")\n",
    "        \n",
    "        # Simulate BCE computation\n",
    "        max_val = torch.clamp(y_hat, min=0)\n",
    "        loss_part1 = (1 - classes) * y_hat\n",
    "        loss_part2 = max_val\n",
    "        loss_part3 = torch.log(torch.exp(-max_val) + torch.exp(y_hat - max_val))\n",
    "        \n",
    "        print(f\"   Loss part 1 (negative term) range: [{loss_part1.min():.6f}, {loss_part1.max():.6f}]\")\n",
    "        print(f\"   Loss part 3 (log term) contains NaN: {torch.isnan(loss_part3).any().item()}\")\n",
    "        \n",
    "    print(f\"{'='*60}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ac855",
   "metadata": {},
   "source": [
    "### **Training Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddbf3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(rnn, optimizer, dev, train_loader, val_loader, batch_size, ecpoh_num):\n",
    "    rnn.train()\n",
    "    loss_arr = []\n",
    "    l1_grad_sq = []\n",
    "    l2_grad_sq = []\n",
    "\n",
    "    i = 0\n",
    "    continue_run = True\n",
    "    enum_train = enumerate(train_loader)\n",
    "    train_size = len(train_loader) - len(train_loader) % batch_size\n",
    "\n",
    "    while i < train_size and continue_run:\n",
    "        try:\n",
    "            # ✅ NOW UNPACKING 3 VALUES: inputs, targets, and sequence lengths\n",
    "            i, (movie_ovw_batch, target_batch, seq_lengths) = next(enum_train)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        # Move batches to device\n",
    "        movie_ovw_batch = movie_ovw_batch.to(dev)\n",
    "        target_batch = target_batch.to(dev)\n",
    "        seq_lengths = seq_lengths.to(dev)\n",
    "\n",
    "        # Prepare targets\n",
    "\n",
    "        #Delete if statement later - checks if dataset contains nan/inf\n",
    "        classes_list = []\n",
    "        if torch.isnan(target_batch).any() or torch.isinf(target_batch).any():\n",
    "            print(f\"\\n{'!'*60}\")\n",
    "            print(f\"NaN/Inf VALUE DETECTED AT TARGET BATCH {i}\")\n",
    "            print(f\"{'!'*60}\")\n",
    "            print(f\"Target batch: {target_batch}\")\n",
    "            \n",
    "\n",
    "            continue_run = False\n",
    "            break\n",
    "\n",
    "        classes_list = create_smoothed_list(target_batch, classes_list)\n",
    "        classes = torch.stack(classes_list).to(dev)\n",
    "\n",
    "        # ✅ Forward Pass WITH sequence lengths\n",
    "        y_hat = rnn.forward(movie_ovw_batch, seq_lengths)\n",
    "\n",
    "        # Loss Calculation\n",
    "        loss_func = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_func(y_hat, classes)\n",
    "\n",
    "        # Check for NaN loss\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            print(f\"\\n{'!'*60}\")\n",
    "            print(f\"NaN/Inf LOSS DETECTED AT BATCH {i}\")\n",
    "            print(f\"{'!'*60}\")\n",
    "            print(f\"Sequence lengths: {seq_lengths}\")\n",
    "            print(f\"Input shape: {movie_ovw_batch.shape}\")\n",
    "            print(f\"Logits range: [{y_hat.min():.4f}, {y_hat.max():.4f}]\")\n",
    "            print(f\"Target batch: {target_batch}\")\n",
    "            diagnose_batch(movie_ovw_batch,y_hat,classes,i)\n",
    "\n",
    "            continue_run = False\n",
    "            break\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Check gradients\n",
    "        if rnn.rnnL1.weight_hh.grad is not None:\n",
    "            grad_norm_l1 = rnn.rnnL1.weight_hh.grad.norm().item() ** 2\n",
    "            grad_norm_l2 = rnn.rnnL2.weight_hh.grad.norm().item() ** 2\n",
    "            \n",
    "            l1_grad_sq.append(grad_norm_l1)\n",
    "            l2_grad_sq.append(grad_norm_l2)\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        loss_arr.append(loss.item())\n",
    "\n",
    "        # Print progress\n",
    "        if (i + 1) % 10 == 0:\n",
    "            avg_seq_len = seq_lengths.float().mean().item()\n",
    "            grad_info = f\"L2 grad²={grad_norm_l2:.6f}\" if rnn.rnnL1.weight_hh.grad is not None else \"No grads\"\n",
    "            print(f\"Epoch {ecpoh_num+1} | Batch {i+1}/{len(train_loader)} | \"\n",
    "                  f\"Loss={loss.item():.6f} | Avg seq len={avg_seq_len:.1f} | {grad_info}\")\n",
    "\n",
    "    print(\"\\nEpoch finished.\")\n",
    "    \n",
    "    # Save tracking data\n",
    "    if len(loss_arr) > 0:\n",
    "        df = pd.DataFrame({\n",
    "            'l1_gradient_sq': l1_grad_sq,\n",
    "            'l2_gradient_sq': l2_grad_sq,\n",
    "            'loss_arr': loss_arr\n",
    "        })\n",
    "        df.to_csv(f\"model_track_epoch_{ecpoh_num}.csv\", index=False, header=True)\n",
    "    \n",
    "    return continue_run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419da48",
   "metadata": {},
   "source": [
    "### **Dataset and DataLoader Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e419da49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from overview_embs.pt\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: This cell pre-processes all movie overviews into embeddings.\n",
    "# This should be run only ONCE to create the 'overview_embs.pt' file.\n",
    "# Running this every time would be very slow.\n",
    "# It saves the embeddings to the CPU to avoid taking up GPU memory.\n",
    "\n",
    "import os\n",
    "\n",
    "embedding_file = \"overview_embs.pt\"\n",
    "\n",
    "if not os.path.exists(embedding_file):\n",
    "    print(\"Embedding file not found. Creating embeddings...\")\n",
    "    overview_ds = []\n",
    "    # Use a temporary model on the correct device for tokenization\n",
    "    temp_model = RNN().to(device)\n",
    "    for i, overview in enumerate(movie_genre_ds[\"overview\"]):\n",
    "        # We move the embeddings to the CPU before storing them in the list\n",
    "        tokenized_ovw = temp_model.tokenize_input(overview, device=device).cpu()\n",
    "        overview_ds.append(tokenized_ovw)\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Processed {i+1}/{len(movie_genre_ds['overview'])} overviews\")\n",
    "    \n",
    "    torch.save(overview_ds, embedding_file)\n",
    "    print(f\"Saved embeddings to {embedding_file}\")\n",
    "    del temp_model # Free up memory\n",
    "else:\n",
    "    print(f\"Loading embeddings from {embedding_file}\")\n",
    "\n",
    "# Load the pre-computed embeddings\n",
    "tokenized_overview_tensors = torch.load(embedding_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c08a3",
   "metadata": {},
   "source": [
    "### **Train RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d5cebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes - Train: 7984, Val: 998, Test: 998\n",
      "Starting training...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 1\n",
      "======================================================================\n",
      "Epoch 1 | Batch 10/998 | Loss=0.394375 | Avg seq len=72.5 | L2 grad²=0.012403\n",
      "Epoch 1 | Batch 20/998 | Loss=0.223173 | Avg seq len=77.1 | L2 grad²=0.013041\n",
      "Epoch 1 | Batch 30/998 | Loss=0.184688 | Avg seq len=84.8 | L2 grad²=0.013573\n",
      "Epoch 1 | Batch 40/998 | Loss=0.195886 | Avg seq len=97.4 | L2 grad²=0.014322\n",
      "Epoch 1 | Batch 50/998 | Loss=0.199011 | Avg seq len=64.2 | L2 grad²=0.014436\n",
      "Epoch 1 | Batch 60/998 | Loss=0.198356 | Avg seq len=86.0 | L2 grad²=0.018499\n",
      "Epoch 1 | Batch 70/998 | Loss=0.185009 | Avg seq len=52.9 | L2 grad²=0.015499\n",
      "Epoch 1 | Batch 80/998 | Loss=0.220273 | Avg seq len=68.9 | L2 grad²=0.014181\n",
      "Epoch 1 | Batch 90/998 | Loss=0.192878 | Avg seq len=58.2 | L2 grad²=0.019997\n",
      "⚠️ Sample 2 in batch has no valid labels (all padding), using uniform distribution\n",
      "Epoch 1 | Batch 100/998 | Loss=0.206879 | Avg seq len=57.5 | L2 grad²=0.016415\n",
      "Epoch 1 | Batch 110/998 | Loss=0.218741 | Avg seq len=72.2 | L2 grad²=0.019362\n",
      "Epoch 1 | Batch 120/998 | Loss=0.194293 | Avg seq len=66.8 | L2 grad²=0.019440\n",
      "Epoch 1 | Batch 130/998 | Loss=0.190219 | Avg seq len=63.5 | L2 grad²=0.019532\n",
      "Epoch 1 | Batch 140/998 | Loss=0.167990 | Avg seq len=77.8 | L2 grad²=0.017076\n",
      "Epoch 1 | Batch 150/998 | Loss=0.180148 | Avg seq len=86.0 | L2 grad²=0.017401\n",
      "Epoch 1 | Batch 160/998 | Loss=0.191448 | Avg seq len=64.6 | L2 grad²=0.015081\n",
      "Epoch 1 | Batch 170/998 | Loss=0.155445 | Avg seq len=83.6 | L2 grad²=0.016723\n",
      "Epoch 1 | Batch 180/998 | Loss=0.187947 | Avg seq len=58.0 | L2 grad²=0.018028\n",
      "Epoch 1 | Batch 190/998 | Loss=0.192384 | Avg seq len=72.6 | L2 grad²=0.018197\n",
      "Epoch 1 | Batch 200/998 | Loss=0.195391 | Avg seq len=88.8 | L2 grad²=0.014747\n",
      "Epoch 1 | Batch 210/998 | Loss=0.163455 | Avg seq len=65.0 | L2 grad²=0.017411\n",
      "Epoch 1 | Batch 220/998 | Loss=0.194007 | Avg seq len=67.0 | L2 grad²=0.015449\n",
      "Epoch 1 | Batch 230/998 | Loss=0.190965 | Avg seq len=76.0 | L2 grad²=0.018908\n",
      "Epoch 1 | Batch 240/998 | Loss=0.197172 | Avg seq len=56.8 | L2 grad²=0.019688\n",
      "Epoch 1 | Batch 250/998 | Loss=0.158072 | Avg seq len=94.0 | L2 grad²=0.016385\n",
      "Epoch 1 | Batch 260/998 | Loss=0.177201 | Avg seq len=66.1 | L2 grad²=0.015600\n",
      "Epoch 1 | Batch 270/998 | Loss=0.173967 | Avg seq len=65.4 | L2 grad²=0.017072\n",
      "Epoch 1 | Batch 280/998 | Loss=0.194947 | Avg seq len=72.1 | L2 grad²=0.018026\n",
      "Epoch 1 | Batch 290/998 | Loss=0.161285 | Avg seq len=69.8 | L2 grad²=0.017421\n",
      "Epoch 1 | Batch 300/998 | Loss=0.144682 | Avg seq len=51.6 | L2 grad²=0.017168\n",
      "Epoch 1 | Batch 310/998 | Loss=0.175249 | Avg seq len=78.9 | L2 grad²=0.018651\n",
      "Epoch 1 | Batch 320/998 | Loss=0.178594 | Avg seq len=46.0 | L2 grad²=0.015014\n",
      "Epoch 1 | Batch 330/998 | Loss=0.176975 | Avg seq len=64.1 | L2 grad²=0.019488\n",
      "Epoch 1 | Batch 340/998 | Loss=0.170583 | Avg seq len=60.2 | L2 grad²=0.016746\n",
      "Epoch 1 | Batch 350/998 | Loss=0.177527 | Avg seq len=76.2 | L2 grad²=0.015319\n",
      "Epoch 1 | Batch 360/998 | Loss=0.171055 | Avg seq len=71.6 | L2 grad²=0.017921\n",
      "Epoch 1 | Batch 370/998 | Loss=0.193509 | Avg seq len=51.5 | L2 grad²=0.019872\n",
      "Epoch 1 | Batch 380/998 | Loss=0.170483 | Avg seq len=56.0 | L2 grad²=0.018639\n",
      "Epoch 1 | Batch 390/998 | Loss=0.176707 | Avg seq len=79.0 | L2 grad²=0.015742\n",
      "Epoch 1 | Batch 400/998 | Loss=0.186024 | Avg seq len=71.5 | L2 grad²=0.015659\n",
      "Epoch 1 | Batch 410/998 | Loss=0.170449 | Avg seq len=82.4 | L2 grad²=0.017297\n",
      "Epoch 1 | Batch 420/998 | Loss=0.176029 | Avg seq len=71.9 | L2 grad²=0.016980\n",
      "Epoch 1 | Batch 430/998 | Loss=0.168719 | Avg seq len=61.5 | L2 grad²=0.014670\n",
      "Epoch 1 | Batch 440/998 | Loss=0.171760 | Avg seq len=63.2 | L2 grad²=0.012941\n",
      "Epoch 1 | Batch 450/998 | Loss=0.174152 | Avg seq len=63.1 | L2 grad²=0.019625\n",
      "Epoch 1 | Batch 460/998 | Loss=0.171132 | Avg seq len=70.6 | L2 grad²=0.013882\n",
      "Epoch 1 | Batch 470/998 | Loss=0.163097 | Avg seq len=69.0 | L2 grad²=0.019865\n",
      "Epoch 1 | Batch 480/998 | Loss=0.181305 | Avg seq len=91.2 | L2 grad²=0.014179\n",
      "Epoch 1 | Batch 490/998 | Loss=0.173540 | Avg seq len=99.2 | L2 grad²=0.017148\n",
      "Epoch 1 | Batch 500/998 | Loss=0.160647 | Avg seq len=77.9 | L2 grad²=0.016838\n",
      "Epoch 1 | Batch 510/998 | Loss=0.173073 | Avg seq len=59.1 | L2 grad²=0.013238\n",
      "Epoch 1 | Batch 520/998 | Loss=0.182117 | Avg seq len=59.8 | L2 grad²=0.015181\n",
      "Epoch 1 | Batch 530/998 | Loss=0.183836 | Avg seq len=54.1 | L2 grad²=0.015603\n",
      "Epoch 1 | Batch 540/998 | Loss=0.180822 | Avg seq len=67.8 | L2 grad²=0.016887\n",
      "Epoch 1 | Batch 550/998 | Loss=0.166691 | Avg seq len=91.4 | L2 grad²=0.014088\n",
      "Epoch 1 | Batch 560/998 | Loss=0.143292 | Avg seq len=64.4 | L2 grad²=0.016845\n",
      "Epoch 1 | Batch 570/998 | Loss=0.157596 | Avg seq len=96.6 | L2 grad²=0.013737\n",
      "Epoch 1 | Batch 580/998 | Loss=0.179255 | Avg seq len=132.2 | L2 grad²=0.014588\n",
      "Epoch 1 | Batch 590/998 | Loss=0.158165 | Avg seq len=73.8 | L2 grad²=0.017479\n",
      "Epoch 1 | Batch 600/998 | Loss=0.185037 | Avg seq len=54.6 | L2 grad²=0.016302\n",
      "Epoch 1 | Batch 610/998 | Loss=0.169846 | Avg seq len=67.9 | L2 grad²=0.016081\n",
      "Epoch 1 | Batch 620/998 | Loss=0.182511 | Avg seq len=84.4 | L2 grad²=0.012983\n",
      "Epoch 1 | Batch 630/998 | Loss=0.166579 | Avg seq len=98.5 | L2 grad²=0.015861\n",
      "Epoch 1 | Batch 640/998 | Loss=0.165899 | Avg seq len=54.8 | L2 grad²=0.015424\n",
      "Epoch 1 | Batch 650/998 | Loss=0.170001 | Avg seq len=71.6 | L2 grad²=0.014773\n",
      "Epoch 1 | Batch 660/998 | Loss=0.165027 | Avg seq len=51.4 | L2 grad²=0.014075\n",
      "⚠️ Sample 3 in batch has no valid labels (all padding), using uniform distribution\n",
      "Epoch 1 | Batch 670/998 | Loss=0.183435 | Avg seq len=49.6 | L2 grad²=0.015653\n",
      "Epoch 1 | Batch 680/998 | Loss=0.172171 | Avg seq len=72.6 | L2 grad²=0.013233\n",
      "Epoch 1 | Batch 690/998 | Loss=0.156555 | Avg seq len=62.9 | L2 grad²=0.013683\n",
      "Epoch 1 | Batch 700/998 | Loss=0.153193 | Avg seq len=78.0 | L2 grad²=0.016059\n",
      "Epoch 1 | Batch 710/998 | Loss=0.165495 | Avg seq len=69.5 | L2 grad²=0.013183\n",
      "Epoch 1 | Batch 720/998 | Loss=0.176347 | Avg seq len=73.6 | L2 grad²=0.012203\n",
      "Epoch 1 | Batch 730/998 | Loss=0.133151 | Avg seq len=66.4 | L2 grad²=0.012748\n",
      "Epoch 1 | Batch 740/998 | Loss=0.160507 | Avg seq len=53.1 | L2 grad²=0.013610\n",
      "Epoch 1 | Batch 750/998 | Loss=0.141623 | Avg seq len=63.2 | L2 grad²=0.012924\n",
      "Epoch 1 | Batch 760/998 | Loss=0.188240 | Avg seq len=99.1 | L2 grad²=0.011993\n",
      "Epoch 1 | Batch 770/998 | Loss=0.146811 | Avg seq len=76.0 | L2 grad²=0.013364\n",
      "Epoch 1 | Batch 780/998 | Loss=0.153694 | Avg seq len=78.9 | L2 grad²=0.017357\n",
      "Epoch 1 | Batch 790/998 | Loss=0.153643 | Avg seq len=93.0 | L2 grad²=0.008160\n",
      "Epoch 1 | Batch 800/998 | Loss=0.159442 | Avg seq len=62.9 | L2 grad²=0.013941\n",
      "Epoch 1 | Batch 810/998 | Loss=0.149910 | Avg seq len=63.0 | L2 grad²=0.012975\n",
      "Epoch 1 | Batch 820/998 | Loss=0.183456 | Avg seq len=56.6 | L2 grad²=0.011661\n",
      "Epoch 1 | Batch 830/998 | Loss=0.168578 | Avg seq len=73.9 | L2 grad²=0.013672\n",
      "Epoch 1 | Batch 840/998 | Loss=0.158266 | Avg seq len=60.0 | L2 grad²=0.008411\n",
      "Epoch 1 | Batch 850/998 | Loss=0.179567 | Avg seq len=91.9 | L2 grad²=0.011673\n",
      "Epoch 1 | Batch 860/998 | Loss=0.178477 | Avg seq len=71.9 | L2 grad²=0.013066\n",
      "Epoch 1 | Batch 870/998 | Loss=0.133854 | Avg seq len=91.1 | L2 grad²=0.011502\n",
      "Epoch 1 | Batch 880/998 | Loss=0.157111 | Avg seq len=53.0 | L2 grad²=0.009872\n",
      "Epoch 1 | Batch 890/998 | Loss=0.161151 | Avg seq len=73.1 | L2 grad²=0.013603\n",
      "Epoch 1 | Batch 900/998 | Loss=0.190525 | Avg seq len=58.0 | L2 grad²=0.012155\n",
      "Epoch 1 | Batch 910/998 | Loss=0.163027 | Avg seq len=76.6 | L2 grad²=0.011437\n",
      "Epoch 1 | Batch 920/998 | Loss=0.164319 | Avg seq len=67.5 | L2 grad²=0.014832\n",
      "Epoch 1 | Batch 930/998 | Loss=0.167823 | Avg seq len=97.9 | L2 grad²=0.011574\n",
      "Epoch 1 | Batch 940/998 | Loss=0.184076 | Avg seq len=61.0 | L2 grad²=0.012090\n",
      "Epoch 1 | Batch 950/998 | Loss=0.158929 | Avg seq len=64.5 | L2 grad²=0.013395\n",
      "Epoch 1 | Batch 960/998 | Loss=0.155227 | Avg seq len=66.5 | L2 grad²=0.014876\n",
      "Epoch 1 | Batch 970/998 | Loss=0.148393 | Avg seq len=68.2 | L2 grad²=0.010474\n",
      "Epoch 1 | Batch 980/998 | Loss=0.170657 | Avg seq len=80.2 | L2 grad²=0.012311\n",
      "Epoch 1 | Batch 990/998 | Loss=0.165696 | Avg seq len=69.0 | L2 grad²=0.011797\n",
      "\n",
      "Epoch finished.\n",
      "\n",
      "Training complete. Saving model...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    BATCH_SIZE = 8\n",
    "    \n",
    "    my_rnn = RNN().to(device)\n",
    "    optimizer = optim.Adam(params=my_rnn.parameters(), lr=5e-6, weight_decay=1e-2)\n",
    "    \n",
    "    full_dataset = MovieOverviewDataset(tokenized_overview_tensors, movie_id_loc)\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = int((len(full_dataset) - train_size) / 2) \n",
    "    test_size = len(full_dataset) - train_size - val_size\n",
    "    \n",
    "    print(f\"Dataset sizes - Train: {train_size}, Val: {val_size}, Test: {test_size}\")\n",
    "    train_ds, test_ds, val_ds = random_split(full_dataset, [train_size, test_size, val_size])\n",
    "    \n",
    "    # ✅ Use the NEW collate_fn that returns sequence lengths\n",
    "    train_loader = DataLoader(dataset=train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                             num_workers=0, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(dataset=test_ds, batch_size=1, shuffle=True, \n",
    "                            num_workers=0, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(dataset=val_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                           num_workers=0, collate_fn=collate_fn)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    for epoch_iter in range(EPOCH_NUMBER):\n",
    "        print(f\"\\n{'='*70}\\nEPOCH {epoch_iter + 1}\\n{'='*70}\")\n",
    "        continue_run = epoch_train(my_rnn, optimizer=optimizer, dev=device, \n",
    "                                   train_loader=train_loader, val_loader=val_loader, \n",
    "                                   batch_size=BATCH_SIZE, ecpoh_num=epoch_iter)\n",
    "        \n",
    "        if not continue_run:\n",
    "            print(f\"Training stopped at epoch {epoch_iter + 1}\")\n",
    "            break\n",
    "    \n",
    "    if continue_run:\n",
    "        print(\"\\nTraining complete. Saving model...\")\n",
    "        torch.save(my_rnn.state_dict(), \"model_parameters.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
