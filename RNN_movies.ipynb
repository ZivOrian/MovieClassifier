{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn transformers datasets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b67dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\orian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from Dependencies.Early_Stop import EarlyStopping\n",
    "from Dependencies.AdditionalFunctions import topK_one_hot, smooth_multi_hot\n",
    "from Dependencies.MovieDataset import MovieGenresDataset\n",
    "from Dependencies.RNN_model_class import RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74bf09",
   "metadata": {},
   "source": [
    "### Initialize Model and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a080ae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e624f5",
   "metadata": {},
   "source": [
    "### Initialize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e332b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgd_ds = MovieGenresDataset()\n",
    "movie_genre_ds = mgd_ds.getDs()\n",
    "movie_id_loc = mgd_ds.get_classes()\n",
    "\n",
    "# This value will be used for padding label sequences\n",
    "pad_value = -1 # Using -1 is safer than a magic number like 5555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5224125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_smoothed_list(target_batch,class_lst):\n",
    "    for target in target_batch:\n",
    "            # Filter out padding values from the target tensor\n",
    "            valid_targets = target[target != pad_value]\n",
    "            one_hot_target = topK_one_hot(valid_targets.cpu().numpy(), 19) # Moving targets to cpu to save memory\n",
    "            smoothed_target = smooth_multi_hot(torch.tensor(one_hot_target), len(valid_targets))\n",
    "            class_lst.append(smoothed_target)\n",
    "    return class_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ac855",
   "metadata": {},
   "source": [
    "### **Training Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(rnn, optimizer, dev, train_loader, val_loader, batch_size):\n",
    "    rnn.train() # Set the model to training mode\n",
    "    loss_arr = []\n",
    "    l1_grad_sq = []\n",
    "    l2_grad_sq = []\n",
    "\n",
    "    i=0\n",
    "    j=0\n",
    "    continue_run = True\n",
    "    enum_train = enumerate(train_loader)\n",
    "\n",
    "    train_size = len(train_loader) - len(train_loader)%batch_size\n",
    "\n",
    "    # Loop that processes the entire batch at once with early stopping\n",
    "    while i-1 < train_size and continue_run:\n",
    "        i, (movie_ovw_batch, target_batch) = next(enum_train)\n",
    "        # Setting up an early stopping class\n",
    "        es = EarlyStopping()\n",
    "        # batching and loading them onto de-facto device (GPU / CPU)\n",
    "        movie_ovw_batch = movie_ovw_batch.to(dev)\n",
    "        target_batch = target_batch.to(dev)\n",
    "\n",
    "        # --- Prepare targets for the entire batch ---\n",
    "        # These lists will hold the processed multi-hot encoded targets for each item in the batch\n",
    "        classes_list = []\n",
    "        classes_list = create_smoothed_list(target_batch ,classes_list)\n",
    "        \n",
    "        # Stack the list of tensors into a single batch tensor\n",
    "        classes = torch.stack(classes_list).to(dev)\n",
    "\n",
    "        # --- Forward Pass ---\n",
    "        y_hat = rnn.forward(movie_ovw_batch)\n",
    "\n",
    "        # --- Loss Calculation ---\n",
    "        loss_func = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_func(y_hat, classes)\n",
    "\n",
    "        # --- Backpropagation ---\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=1.0) # Gradient clipping\n",
    "        \n",
    "        # Store the layer's squared gradient norm *before* the optimizer step\n",
    "        if rnn.rnnL1.weight_hh.grad is not None:\n",
    "            l1_grad_sq.append(rnn.rnnL1.weight_hh.grad.norm().item()**2)\n",
    "            l2_grad_sq.append(rnn.rnnL2.weight_hh.grad.norm().item()**2)\n",
    "        \n",
    "        # --- Optimizer step ---\n",
    "        \n",
    "        \"\"\"if not math.isnan(rnn.rnnL2.weight_hh.grad.norm().item()**2):\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            print(f\"These are the logits{y_hat}\\n\\nThis is the input: {movie_ovw_batch}\")\n",
    "            problemo_df = pd.DataFrame({\n",
    "                'problemo_yhat':y_hat,\n",
    "                'problemo_ovw':movie_ovw_batch\n",
    "            })\n",
    "            continue_run=False\n",
    "        \"\"\"\n",
    "        \n",
    "        loss_arr.append(loss.item())\n",
    "        \n",
    "        # Print progress every 10 batches\n",
    "        if (i + 1) % 10 == 0: \n",
    "            print(f\"Batch {i+1}/{len(train_loader)},gradient = {rnn.rnnL2.weight_hh.grad.norm().item()**2}, Loss = {loss.item():.4f}\")\n",
    "            \n",
    "            print(rnn.rnnL2.weight_hh.grad.norm() ,math.isnan(rnn.rnnL2.weight_hh.grad.norm().item()**2))\n",
    "            # For debugging memory, uncomment the line below:\n",
    "            # print(torch.cuda.memory_summary(device=dev))\n",
    "\n",
    "\n",
    "        # ----- Validation Section ----- \n",
    "        #     (done per step count)\n",
    "        \n",
    "        # Validate model with a validation batch every 50 batches\n",
    "        \"\"\"if i%200==0 and i!=0 and j<len(val_loader.dataset):\n",
    "            rnn.eval()#setting model to evaluation mode\n",
    "\n",
    "            j, (val_movie_ovw_batch, val_target_batch) = next(enumerate(val_loader))\n",
    "            val_movie_ovw_batch = val_movie_ovw_batch.to(dev)\n",
    "            val_target_batch = val_target_batch.to(dev)\n",
    "\n",
    "            val_class_lst = []\n",
    "            val_class_lst = create_smoothed_list(val_target_batch, val_class_lst)\n",
    "            valuation_classes = torch.stack(val_class_lst).to(dev)\n",
    "            with torch.no_grad():\n",
    "                print(f\"yep. that's the shape - {val_movie_ovw_batch.shape}\")\n",
    "                val_y_hat = rnn.forward(val_movie_ovw_batch)\n",
    "                vloss = loss_func(val_y_hat, valuation_classes)\n",
    "                # Set the continue boolean to false if the model worsens\n",
    "                continue_run = es(rnn, vloss)\n",
    "\n",
    "            rnn.train()# set the model back to training mode\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"Epoch finished.\")\n",
    "    # Save tracking data\n",
    "    df = pd.DataFrame({\n",
    "        'l1_gradient_sq': l1_grad_sq,\n",
    "        'l2_gradient_sq': l2_grad_sq,\n",
    "        'loss_arr': loss_arr\n",
    "    })\n",
    "    \"\"\"if problemo_df:\n",
    "        problemo_df.to_csv(\"problemo.csv\", index=True, header=True)\"\"\"\n",
    "    df.to_csv(\"track.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419da48",
   "metadata": {},
   "source": [
    "### **Dataset and DataLoader Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc887c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class MovieOverviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_overviews, id_loc_set):\n",
    "        self.tokenized_ovw = tokenized_overviews\n",
    "        self.id_loc_set = id_loc_set\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenized_ovw[idx], torch.tensor(self.id_loc_set[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id_loc_set)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    \n",
    "    # Pad sequences (features)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    \n",
    "    # Pad labels (targets)\n",
    "    padded_labels = pad_sequence(labels, batch_first=True, padding_value=pad_value)\n",
    "    \n",
    "    return padded_sequences, padded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e419da49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from overview_embs.pt\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: This cell pre-processes all movie overviews into embeddings.\n",
    "# This should be run only ONCE to create the 'overview_embs.pt' file.\n",
    "# Running this every time would be very slow.\n",
    "# It saves the embeddings to the CPU to avoid taking up GPU memory.\n",
    "\n",
    "import os\n",
    "\n",
    "embedding_file = \"overview_embs.pt\"\n",
    "\n",
    "if not os.path.exists(embedding_file):\n",
    "    print(\"Embedding file not found. Creating embeddings...\")\n",
    "    overview_ds = []\n",
    "    # Use a temporary model on the correct device for tokenization\n",
    "    temp_model = RNN().to(device)\n",
    "    for i, overview in enumerate(movie_genre_ds[\"overview\"]):\n",
    "        # We move the embeddings to the CPU before storing them in the list\n",
    "        tokenized_ovw = temp_model.tokenize_input(overview, device=device).cpu()\n",
    "        overview_ds.append(tokenized_ovw)\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Processed {i+1}/{len(movie_genre_ds['overview'])} overviews\")\n",
    "    \n",
    "    torch.save(overview_ds, embedding_file)\n",
    "    print(f\"Saved embeddings to {embedding_file}\")\n",
    "    del temp_model # Free up memory\n",
    "else:\n",
    "    print(f\"Loading embeddings from {embedding_file}\")\n",
    "\n",
    "# Load the pre-computed embeddings\n",
    "tokenized_overview_tensors = torch.load(embedding_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c08a3",
   "metadata": {},
   "source": [
    "### **Train RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d5cebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998\n",
      "Starting training...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m np.set_printoptions(threshold=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mepoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining complete. Saving model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m torch.save(my_rnn.state_dict(), \u001b[33m\"\u001b[39m\u001b[33mmodel_parameters.pt\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mepoch_train\u001b[39m\u001b[34m(rnn, optimizer, dev, train_loader, val_loader, batch_size)\u001b[39m\n\u001b[32m     12\u001b[39m train_size = \u001b[38;5;28mlen\u001b[39m(train_loader) - \u001b[38;5;28mlen\u001b[39m(train_loader)%batch_size\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Loop that processes the entire batch at once with early stopping\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m i-\u001b[32m1\u001b[39m<-\u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain\u001b[49m) \u001b[38;5;129;01mand\u001b[39;00m continue_run:\n\u001b[32m     16\u001b[39m     i, (movie_ovw_batch, target_batch) = \u001b[38;5;28mnext\u001b[39m(enum_train)\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Setting up an early stopping class\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    BATCH_SIZE = 4 # Defining batch size as a variable\n",
    "\n",
    "    my_rnn = RNN().to(device)\n",
    "    optimizer = optim.Adam(params=my_rnn.parameters(), lr=2.5e-4, weight_decay=1.5e-4)\n",
    "\n",
    "    # Create the dataset instance with the pre-loaded embeddings\n",
    "    full_dataset = MovieOverviewDataset(tokenized_overview_tensors, movie_id_loc)\n",
    "\n",
    "    # Split dataset into train, test and validation datasets\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = int((len(full_dataset) - train_size)/2) \n",
    "    test_size = len(full_dataset) - train_size - val_size\n",
    "    \n",
    "\n",
    "    print(val_size)\n",
    "    train_ds, test_ds, val_ds = random_split(full_dataset, [train_size, test_size, val_size])\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(dataset=train_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(dataset=test_ds, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(dataset=test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    np.set_printoptions(threshold=None)\n",
    "    print(\"Starting training...\")\n",
    "    epoch_train(my_rnn, optimizer=optimizer, dev=device, train_loader=train_loader, val_loader=val_loader, batch_size=BATCH_SIZE)\n",
    "\n",
    "    \n",
    "    print(\"Training complete. Saving model...\")\n",
    "    torch.save(my_rnn.state_dict(), \"model_parameters.pt\")\n",
    "    print(\"Model saved to model_parameters.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
