{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc1c0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.56.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\orian\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\orian\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\orian\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\orian\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\orian\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn transformers datasets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b67dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\orian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import ast\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from Dependencies.Early_Stop import EarlyStopping\n",
    "from Dependencies.AdditionalFunctions import topK_one_hot, smooth_multi_hot\n",
    "from Dependencies.MovieDataset import MovieGenresDataset\n",
    "from Dependencies.RNN_model_class import RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74bf09",
   "metadata": {},
   "source": [
    "### Initialize Model and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a080ae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "my_rnn = RNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e624f5",
   "metadata": {},
   "source": [
    "### Initialize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e332b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgd_ds = MovieGenresDataset()\n",
    "movie_genre_ds = mgd_ds.getDs()\n",
    "movie_id_loc = mgd_ds.get_classes()\n",
    "\n",
    "# This value will be used for padding label sequences\n",
    "pad_value = -1 # Using -1 is safer than a magic number like 5555"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ac855",
   "metadata": {},
   "source": [
    "### **Training Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(rnn, optimizer, dev, train_loader, val_loader, batch_size):\n",
    "    rnn.train() # Set the model to training mode\n",
    "    loss_arr = []\n",
    "    l1_grad_sq = []\n",
    "    l2_grad_sq = []\n",
    "\n",
    "    # --- MEMORY & EFFICIENCY FIX: BATCH-CENTRIC TRAINING --- \n",
    "    # The original code iterated one-by-one inside a batch, which is inefficient \n",
    "    # and can lead to memory issues. This new loop processes the entire batch at once.\n",
    "    i, (movie_ovw_tot, target_tot) = enumerate(train_loader)\n",
    "    continue_run = True\n",
    "\n",
    "    while i<len(train_loader) and continue_run:\n",
    "        es = EarlyStopping()\n",
    "        # Move data at iteration i to the de-facto device (GPU / CPU)\n",
    "        movie_ovw_batch = movie_ovw_tot[i].to(dev)\n",
    "        target_batch = target_tot[i].to(dev)\n",
    "\n",
    "        # --- Prepare targets for the entire batch ---\n",
    "        # This list will hold the processed multi-hot encoded targets for each item in the batch\n",
    "        classes_list = []\n",
    "        for target in target_batch:\n",
    "            # Filter out padding values from the target tensor\n",
    "            valid_targets = target[target != pad_value]\n",
    "            one_hot_target = topK_one_hot(valid_targets.cpu().numpy(), 19) # Assuming topK works with numpy\n",
    "            smoothed_target = smooth_multi_hot(torch.tensor(one_hot_target), len(valid_targets))\n",
    "            classes_list.append(smoothed_target)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Stack the list of tensors into a single batch tensor\n",
    "        classes = torch.stack(classes_list).to(dev)\n",
    "\n",
    "        # --- Forward Pass ---\n",
    "        y_hat = rnn.forward(movie_ovw_batch)\n",
    "\n",
    "        # --- Loss Calculation ---\n",
    "        loss_func = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_func(y_hat, classes)\n",
    "\n",
    "        # --- Backpropagation ---\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=1e-4) # Gradient clipping\n",
    "        \n",
    "        # Store the layer's squared gradient norm *before* the optimizer step\n",
    "        if rnn.rnnL1.weight_hh.grad is not None:\n",
    "            l1_grad_sq.append(rnn.rnnL1.weight_hh.grad.norm().item()**2)\n",
    "            l2_grad_sq.append(rnn.rnnL2.weight_hh.grad.norm().item()**2)\n",
    "        \n",
    "        # --- Optimizer step ---\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_arr.append(loss.item())\n",
    "        \n",
    "        # Print progress every 10 batches\n",
    "        if (i + 1) % 10 == 0: \n",
    "            print(f\"Batch {i+1}/{len(train_loader)},gradient = {rnn.rnnL2.weight_hh.grad.norm().item()**2}, Loss = {loss.item():.4f}\")\n",
    "            # For debugging memory, uncomment the line below:\n",
    "            # print(torch.cuda.memory_summary(device=dev))\n",
    "\n",
    "        # Validation and early stopping\n",
    "        rnn.eval()#set the model to evaluation mode\n",
    "        with torch.nograd():\n",
    "            vloss = \n",
    "            continue_run = es(rnn, vloss)\n",
    "        rnn.train()# set the model back to training mode\n",
    "    \n",
    "\n",
    "    print(\"Epoch finished.\")\n",
    "    # Save tracking data\n",
    "    df = pd.DataFrame({\n",
    "        'l1_gradient_sq': l1_grad_sq,\n",
    "        'l2_gradient_sq': l2_grad_sq,\n",
    "        'loss_arr': loss_arr\n",
    "    })\n",
    "    df.to_csv(\"track.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419da48",
   "metadata": {},
   "source": [
    "### **Dataset and DataLoader Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc887c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class MovieOverviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_overviews, id_loc_set):\n",
    "        self.tokenized_ovw = tokenized_overviews\n",
    "        self.id_loc_set = id_loc_set\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenized_ovw[idx], torch.tensor(self.id_loc_set[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id_loc_set)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    \n",
    "    # Pad sequences (features)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    \n",
    "    # Pad labels (targets)\n",
    "    padded_labels = pad_sequence(labels, batch_first=True, padding_value=pad_value)\n",
    "    \n",
    "    return padded_sequences, padded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419da49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: This cell pre-processes all movie overviews into embeddings.\n",
    "# This should be run only ONCE to create the 'overview_embs.pt' file.\n",
    "# Running this every time would be very slow.\n",
    "# It saves the embeddings to the CPU to avoid taking up GPU memory.\n",
    "\n",
    "import os\n",
    "\n",
    "embedding_file = \"overview_embs.pt\"\n",
    "\n",
    "if not os.path.exists(embedding_file):\n",
    "    print(\"Embedding file not found. Creating embeddings...\")\n",
    "    overview_ds = []\n",
    "    # Use a temporary model on the correct device for tokenization\n",
    "    temp_model = RNN().to(device)\n",
    "    for i, overview in enumerate(movie_genre_ds[\"overview\"]):\n",
    "        # We move the embeddings to the CPU before storing them in the list\n",
    "        tokenized_ovw = temp_model.tokenize_input(overview, device=device).cpu()\n",
    "        overview_ds.append(tokenized_ovw)\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Processed {i+1}/{len(movie_genre_ds['overview'])} overviews\")\n",
    "    \n",
    "    torch.save(overview_ds, embedding_file)\n",
    "    print(f\"Saved embeddings to {embedding_file}\")\n",
    "    del temp_model # Free up memory\n",
    "else:\n",
    "    print(f\"Loading embeddings from {embedding_file}\")\n",
    "\n",
    "# Load the pre-computed embeddings\n",
    "tokenized_overview_tensors = torch.load(embedding_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c08a3",
   "metadata": {},
   "source": [
    "### **Train RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ignite.engine import Engine, Events\n",
    "#from ignite.handlers import EarlyStopping\n",
    "\n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['nll']\n",
    "    return -val_loss\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BATCH_SIZE = 4 # Defining batch size as a variable\n",
    "\n",
    "    optimizer = optim.Adam(params=my_rnn.parameters(), lr=0.001, weight_decay=1.e-4)\n",
    "\n",
    "    # Create the dataset instance with the pre-loaded embeddings\n",
    "    full_dataset = MovieOverviewDataset(tokenized_overview_tensors, movie_id_loc)\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = test_size = int((len(full_dataset) - train_size)/2)\n",
    "\n",
    "    print(val_size)\n",
    "    train_ds, test_ds, val_ds = random_split(full_dataset, [train_size, test_size, val_size])\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(dataset=train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(dataset=test_ds, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(dataset=test_ds, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    epoch_train(my_rnn, optimizer=optimizer, dev=device, train_loader=train_loader, val_loader=val_loader, batch_size=BATCH_SIZE)\n",
    "\n",
    "    #handler = EarlyStopping(patience=10, score_function=score_function, trainer=trainer)\n",
    "    # Note: the handler is attached to an *Evaluator* (runs one epoch on validation dataset).\n",
    "    #evaluator.add_event_handler(Events.COMPLETED, handler)\n",
    "    \n",
    "    print(\"Training complete. Saving model...\")\n",
    "    torch.save(my_rnn.state_dict(), \"model_parameters.pt\")\n",
    "    print(\"Model saved to model_parameters.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
